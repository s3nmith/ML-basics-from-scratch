# Machine Learning Basics from Scratch

This repo will have all the code that I used to learn about neural networks and machine learning. Some implementations use no libraries and only basic mathematical operations and loops, while others use libraries to make calculations simpler.

## Table of Contents

- [Basic Gradient Descent](#gradient-descent)
- [Update Formula with Loops and Numpy](#update-formula)
- [Basic House Prediction System](#machine-learning-basics)
- [Activation Function](#neural-networks)
- [Shallow Neural Network](#implementation)




## Loss Function and Gradient-Descent

This section is about how the learning happens and how the loss function is minimized via gradient descent.

## Update Formula

My Implementation:




## Neural Networks

Neural networks are a key component of modern machine learning. In this section, we delve into the theory behind neural networks, including:

- Neurons and activation functions
- Feedforward and backpropagation
- Gradient descent
- Regularization techniques
- Hyperparameter tuning

## Implementation

In the implementation section, we provide a step-by-step guide to building neural networks from scratch using Python. The implementation covers:

- Building a neural network architecture
- Initializing weights and biases
- Forward propagation
- Calculating loss and implementing backpropagation
- Updating weights and biases using gradient descent


