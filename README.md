# Machine Learning Basics from Scratch

This repo will have all the code that I used to learn about neural networks and machine learning. Some implementations use no libraries and only basic mathematical operations, while others use libraries to make calculations simpler.

## Table of Contents

- [Basic Gradient Descent](#introduction)
- [Update Formulas with Loops and Numpy](#getting-started)
- [Basic House Prediction System](#machine-learning-basics)
- [Activation Function](#neural-networks)
- [Shallow Neural Network](#implementation)




## Introduction

In this repository, we explore the fundamentals of machine learning and focus on implementing neural networks from scratch. Understanding the basics of machine learning and building neural networks from scratch can provide a solid foundation for working with more complex machine learning models and frameworks.

## Getting Started

To get started with this project, follow these steps:

1. Clone the repository: `git clone https://github.com/your-username/your-repository.git`
2. Install the required dependencies: `pip install -r requirements.txt`
3. [Optional] Set up a virtual environment: `python -m venv env` and activate it.
4. Open the project in your preferred IDE or editor.


## Neural Networks

Neural networks are a key component of modern machine learning. In this section, we delve into the theory behind neural networks, including:

- Neurons and activation functions
- Feedforward and backpropagation
- Gradient descent
- Regularization techniques
- Hyperparameter tuning

## Implementation

In the implementation section, we provide a step-by-step guide to building neural networks from scratch using Python. The implementation covers:

- Building a neural network architecture
- Initializing weights and biases
- Forward propagation
- Calculating loss and implementing backpropagation
- Updating weights and biases using gradient descent

## License

This project is licensed under the [MIT License](LICENSE).
