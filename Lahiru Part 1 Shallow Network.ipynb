{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, yhat):\n",
    "    yloss = -1 * (((1-y) * np.log(1-yhat)) + (y * np.log(yhat)))\n",
    "    return yloss   \n",
    "\n",
    "def cost(Y, Yhat):\n",
    "    Jcost = np.sum(loss(Y, Yhat))/Y.shape[0]\n",
    "    return Jcost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_activation(yhat):    \n",
    "    return yhat\n",
    "unit_activation = np.vectorize(unit_activation)\n",
    "\n",
    "def sigmoid_activation(yhat):    \n",
    "    return 1/(1+np.exp(-yhat))\n",
    "sigmoid_activation = np.vectorize(sigmoid_activation)\n",
    "\n",
    "def relu_activation(yhat):    \n",
    "    return yhat * (yhat > 0)\n",
    "relu_activation = np.vectorize(relu_activation)\n",
    "\n",
    "def TanH(x):\n",
    "    top = np.exp(x) - np.exp(-x)\n",
    "    bottom = np.exp(x) + np.exp(-x)\n",
    "    final = top/bottom\n",
    "    return final\n",
    "TanH = np.vectorize(TanH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derTanH(x):\n",
    "    v = 1 - ((TanH(x))**2)\n",
    "    return v\n",
    "derTanH = np.vectorize(derTanH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Matrices for Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  2\n",
      "Number of Training Examples:  320\n",
      "Number of Test Examples:  80\n"
     ]
    }
   ],
   "source": [
    "X = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[0:320,0:2].T \n",
    "Y = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[0:320,2:3].T \n",
    "\n",
    "Xt = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[320:400,0:2].T \n",
    "Yt = np.genfromtxt('pattern_rand.csv',delimiter=',', skip_header=True)[320:400,2:3].T \n",
    "    \n",
    "n = X.shape[0]\n",
    "m = X.shape[1]\n",
    "t = Xt.shape[1]\n",
    "\n",
    "print(\"Number of Features: \", n)\n",
    "print(\"Number of Training Examples: \", m)\n",
    "print(\"Number of Test Examples: \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Running Forward Propagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterations\n",
    "h = 1000\n",
    "alpha = 0.3\n",
    "# Initialization of J and Yhat\n",
    "J = np.zeros((1,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Structure:\n",
      "IL0: Number of inputs to Layer 0: 2\n",
      "NL0: Number of neurons in Layer 0: 2\n",
      "IL1: Number of inputs to Layer 1: 2\n",
      "NL1: Number of neurons in Layer 1: 12\n",
      "IL2: Number of inputs to Layer 2: 12\n",
      "NL2: Number of neurons in Layer 2: 1\n"
     ]
    }
   ],
   "source": [
    "# IL0: Number of inputs to Layer 0\n",
    "# NL0: Number of neurons in Layer 0\n",
    "IL0 = n\n",
    "NL0 = n\n",
    "# The first layer is input layer so both number of inputs \n",
    "# and number of neurons are equal to number of features\n",
    "\n",
    "# IL1: Number of inputs to Layer 1\n",
    "# NL1: Number of neurons in Layer 1\n",
    "IL1 = NL0\n",
    "NL1 = 12\n",
    "# As there are n neurons in the previous layer, the number\n",
    "# of inputs to Layer 1 is equal to n. Number of neurons\n",
    "# may be any. \n",
    "\n",
    "# IL2: Number of inputs to Layer 2\n",
    "# NL2: Number of neurons in Layer 2\n",
    "IL2 = NL1\n",
    "NL2 = 1\n",
    "# Number of inputs in Layer 2 equals to number of neurons in\n",
    "# the previous layer (one input coming from each neuron). As \n",
    "# this is binary classification with a single output, the number \n",
    "# of neurons equals 1. \n",
    "\n",
    "print(\"Network Structure:\")\n",
    "print(\"IL0: Number of inputs to Layer 0:\", IL0)\n",
    "print(\"NL0: Number of neurons in Layer 0:\", NL0)\n",
    "print(\"IL1: Number of inputs to Layer 1:\", IL1)\n",
    "print(\"NL1: Number of neurons in Layer 1:\", NL1)\n",
    "print(\"IL2: Number of inputs to Layer 2:\", IL2)\n",
    "print(\"NL2: Number of neurons in Layer 2:\", NL2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and Biases:\n",
      "Layer 0: \n",
      "B0\n",
      " [[0.]\n",
      " [0.]]\n",
      "W0\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Layer 1: \n",
      "B1\n",
      " [[0.5488135 ]\n",
      " [0.71518937]\n",
      " [0.60276338]\n",
      " [0.54488318]\n",
      " [0.4236548 ]\n",
      " [0.64589411]\n",
      " [0.43758721]\n",
      " [0.891773  ]\n",
      " [0.96366276]\n",
      " [0.38344152]\n",
      " [0.79172504]\n",
      " [0.52889492]]\n",
      "W1\n",
      " [[0.56804456 0.92559664]\n",
      " [0.07103606 0.0871293 ]\n",
      " [0.0202184  0.83261985]\n",
      " [0.77815675 0.87001215]\n",
      " [0.97861834 0.79915856]\n",
      " [0.46147936 0.78052918]\n",
      " [0.11827443 0.63992102]\n",
      " [0.14335329 0.94466892]\n",
      " [0.52184832 0.41466194]\n",
      " [0.26455561 0.77423369]\n",
      " [0.45615033 0.56843395]\n",
      " [0.0187898  0.6176355 ]]\n",
      "Layer 2: \n",
      "B2\n",
      " [[0.61209572]]\n",
      "W2\n",
      " [[0.616934   0.94374808 0.6818203  0.3595079  0.43703195 0.6976312\n",
      "  0.06022547 0.66676672 0.67063787 0.21038256 0.1289263  0.31542835]]\n"
     ]
    }
   ],
   "source": [
    "# Layer 0 is input layer so W0 is identity matrix while B0 is zero matrix.\n",
    "# Layer 0 in a way simply reproduces its inputs at the output\n",
    "np.random.seed(0)\n",
    "B0 = np.zeros((NL0, 1))\n",
    "W0 = np.identity((NL0))\n",
    "\n",
    "# Layer 1 is a passthrough layer. As number of inputs to the layer equals\n",
    "# 2 and number of neurons are 4, the size of W1 will be 4 x2. To make this\n",
    "# layer a passthrough layer, the 4 x 2 W1 matrix needs to consist of a \n",
    "# a 2 x 2 identity matrix and a 2 x 2 zero matrix. Also B1 is a zero matrix\n",
    "B1 = np.random.rand(NL1,1)\n",
    "W1 =np.random.rand(NL1,IL1)\n",
    "\n",
    "\n",
    "# Layer 2 is a simple Logistic Regression Unit. W2 and B2 are intialized as ones.\n",
    "B2 = np.random.rand(NL2,1)\n",
    "W2 = np.random.rand(NL2,IL2)\n",
    "\n",
    "print(\"Weights and Biases:\")\n",
    "print(\"Layer 0: \")\n",
    "print(\"B0\\n\", B0)\n",
    "print(\"W0\\n\", W0)\n",
    "print(\"Layer 1: \")\n",
    "print(\"B1\\n\", B1)\n",
    "print(\"W1\\n\", W1)\n",
    "print(\"Layer 2: \")\n",
    "print(\"B2\\n\", B2)\n",
    "print(\"W2\\n\", W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jcost = 0.30196115946862073\n",
      "B2 = [[0.07931825]]\n",
      "W2 =  [[ 1.26248658  3.69278534  2.20661077 -1.48460239 -1.45698165  1.38810279\n",
      "  -0.53930412  1.79822875  0.10141899 -0.51314716 -0.96334129 -0.4425899 ]]\n"
     ]
    }
   ],
   "source": [
    "# We now runs a loop for performing forward- and backpropagation\n",
    "for g in range(h):\n",
    "    # Forward propagation \n",
    "    X0 = X\n",
    "    G0 = np.matmul(W0,X0) + B0\n",
    "    H0 = unit_activation(G0)\n",
    "    \n",
    "    #Layer 1\n",
    "    X1 = H0\n",
    "    G1 = np.matmul(W1,X1) + B1\n",
    "    H1 = TanH(G1)\n",
    "    \n",
    "    #Layer 3\n",
    "    X2 = H1\n",
    "    G2 = np.matmul(W2,X2) + B2\n",
    "    H2 = sigmoid_activation(G2)\n",
    "    Yhat = H2\n",
    "\n",
    "    # Determine Cost\n",
    "    J[0,g] = cost(Y, Yhat)/m\n",
    "    \n",
    "    # Layer 2 Backpropagation \n",
    "    dJdG2 = Yhat - Y\n",
    "    dJdB2 =  np.sum(dJdG2, axis = 1, keepdims = True)/m \n",
    "    dJdW2 = np.matmul(dJdG2, X2.T)/m\n",
    "    B2 = B2 - alpha * dJdB2\n",
    "    W2 = W2 - alpha * dJdW2\n",
    "    \n",
    "    #Layer 1 Backward Prop \n",
    "    dJdG1 = np.matmul(W2.T, dJdG2) * derTanH(G1)\n",
    "    dJdB1 =  np.sum(dJdG1, axis = 1, keepdims = True)/m \n",
    "    dJdW1 = np.matmul(dJdG1, X1.T)/m\n",
    "    B1 = B1 - alpha * dJdB1\n",
    "    W1 = W1 - alpha * dJdW1\n",
    "\n",
    "Yhat = np.dot(W1,X1) + B1\n",
    "Yhat = TanH(Yhat)\n",
    "Yhat = np.dot(W2, X2) + B2\n",
    "Yhat = sigmoid_activation(Yhat)\n",
    "J[0][g] = np.sum(loss(Y, Yhat))/m\n",
    "    \n",
    "print(\"Jcost = {}\".format(J[0,h-1]))\n",
    "print(\"B2 = {}\".format(B2))\n",
    "print(\"W2 = \", W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jcost = 0.6636268397430334  \n",
    "B2 = [[-0.00078031]]  \n",
    "W2 =  [[ 0.08056205 -0.24098459  1.          1.        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(J[0, 0:h-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Predictions\n",
    "\n",
    "X0 = Xt\n",
    "G0 = np.matmul(W0,X0) + B0\n",
    "H0 = unit_activation(G0)\n",
    "    \n",
    "X1 = H0\n",
    "G1 = np.matmul(W1,X1) + B1\n",
    "H1 = TanH(G1)\n",
    "Yhat1 = H1\n",
    "    \n",
    "    \n",
    "#Layer 2\n",
    "X2 = H1\n",
    "G2 = np.matmul(W2,X2) + B2\n",
    "Ythat = sigmoid_activation(G2)\n",
    "Ythis = []\n",
    "\n",
    "for i in range(Xt.shape[1]):\n",
    "    if Ythat[0,i] >= 0.5:\n",
    "        Ythis.append(1.0)\n",
    "    else:\n",
    "        Ythis.append(0.0)\n",
    "Ythis = np.array(Ythis).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.5%\n"
     ]
    }
   ],
   "source": [
    "total = Yt.shape[1]\n",
    "error = np.sum(abs(Yt - Ythis))\n",
    "print(\"Accuracy: {}%\".format((total-error)*100/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
